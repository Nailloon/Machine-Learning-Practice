{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e95da14c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "# для оценки качества решения задачи регрессии\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "# для оценки качества решения задачи классификации\n",
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03812293",
   "metadata": {},
   "source": [
    "**Регресия"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "14b8f466",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>price</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>sqft_living</th>\n",
       "      <th>sqft_lot</th>\n",
       "      <th>floors</th>\n",
       "      <th>waterfront</th>\n",
       "      <th>view</th>\n",
       "      <th>...</th>\n",
       "      <th>grade</th>\n",
       "      <th>sqft_above</th>\n",
       "      <th>sqft_basement</th>\n",
       "      <th>yr_built</th>\n",
       "      <th>yr_renovated</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>sqft_living15</th>\n",
       "      <th>sqft_lot15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7129300520</td>\n",
       "      <td>2014</td>\n",
       "      <td>221900.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1180</td>\n",
       "      <td>5650</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>1180</td>\n",
       "      <td>0</td>\n",
       "      <td>1955</td>\n",
       "      <td>0</td>\n",
       "      <td>98178</td>\n",
       "      <td>47.5112</td>\n",
       "      <td>-122.257</td>\n",
       "      <td>1340</td>\n",
       "      <td>5650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6414100192</td>\n",
       "      <td>2014</td>\n",
       "      <td>538000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.25</td>\n",
       "      <td>2570</td>\n",
       "      <td>7242</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>2170</td>\n",
       "      <td>400</td>\n",
       "      <td>1951</td>\n",
       "      <td>1991</td>\n",
       "      <td>98125</td>\n",
       "      <td>47.7210</td>\n",
       "      <td>-122.319</td>\n",
       "      <td>1690</td>\n",
       "      <td>7639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5631500400</td>\n",
       "      <td>2015</td>\n",
       "      <td>180000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.00</td>\n",
       "      <td>770</td>\n",
       "      <td>10000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>770</td>\n",
       "      <td>0</td>\n",
       "      <td>1933</td>\n",
       "      <td>0</td>\n",
       "      <td>98028</td>\n",
       "      <td>47.7379</td>\n",
       "      <td>-122.233</td>\n",
       "      <td>2720</td>\n",
       "      <td>8062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2487200875</td>\n",
       "      <td>2014</td>\n",
       "      <td>604000.0</td>\n",
       "      <td>4</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1960</td>\n",
       "      <td>5000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>1050</td>\n",
       "      <td>910</td>\n",
       "      <td>1965</td>\n",
       "      <td>0</td>\n",
       "      <td>98136</td>\n",
       "      <td>47.5208</td>\n",
       "      <td>-122.393</td>\n",
       "      <td>1360</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1954400510</td>\n",
       "      <td>2015</td>\n",
       "      <td>510000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1680</td>\n",
       "      <td>8080</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>1680</td>\n",
       "      <td>0</td>\n",
       "      <td>1987</td>\n",
       "      <td>0</td>\n",
       "      <td>98074</td>\n",
       "      <td>47.6168</td>\n",
       "      <td>-122.045</td>\n",
       "      <td>1800</td>\n",
       "      <td>7503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21608</th>\n",
       "      <td>263000018</td>\n",
       "      <td>2014</td>\n",
       "      <td>360000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.50</td>\n",
       "      <td>1530</td>\n",
       "      <td>1131</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>1530</td>\n",
       "      <td>0</td>\n",
       "      <td>2009</td>\n",
       "      <td>0</td>\n",
       "      <td>98103</td>\n",
       "      <td>47.6993</td>\n",
       "      <td>-122.346</td>\n",
       "      <td>1530</td>\n",
       "      <td>1509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21609</th>\n",
       "      <td>6600060120</td>\n",
       "      <td>2015</td>\n",
       "      <td>400000.0</td>\n",
       "      <td>4</td>\n",
       "      <td>2.50</td>\n",
       "      <td>2310</td>\n",
       "      <td>5813</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>2310</td>\n",
       "      <td>0</td>\n",
       "      <td>2014</td>\n",
       "      <td>0</td>\n",
       "      <td>98146</td>\n",
       "      <td>47.5107</td>\n",
       "      <td>-122.362</td>\n",
       "      <td>1830</td>\n",
       "      <td>7200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21610</th>\n",
       "      <td>1523300141</td>\n",
       "      <td>2014</td>\n",
       "      <td>402101.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1020</td>\n",
       "      <td>1350</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>1020</td>\n",
       "      <td>0</td>\n",
       "      <td>2009</td>\n",
       "      <td>0</td>\n",
       "      <td>98144</td>\n",
       "      <td>47.5944</td>\n",
       "      <td>-122.299</td>\n",
       "      <td>1020</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21611</th>\n",
       "      <td>291310100</td>\n",
       "      <td>2015</td>\n",
       "      <td>400000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.50</td>\n",
       "      <td>1600</td>\n",
       "      <td>2388</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>1600</td>\n",
       "      <td>0</td>\n",
       "      <td>2004</td>\n",
       "      <td>0</td>\n",
       "      <td>98027</td>\n",
       "      <td>47.5345</td>\n",
       "      <td>-122.069</td>\n",
       "      <td>1410</td>\n",
       "      <td>1287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21612</th>\n",
       "      <td>1523300157</td>\n",
       "      <td>2014</td>\n",
       "      <td>325000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1020</td>\n",
       "      <td>1076</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>1020</td>\n",
       "      <td>0</td>\n",
       "      <td>2008</td>\n",
       "      <td>0</td>\n",
       "      <td>98144</td>\n",
       "      <td>47.5941</td>\n",
       "      <td>-122.299</td>\n",
       "      <td>1020</td>\n",
       "      <td>1357</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21613 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               id  date     price  bedrooms  bathrooms  sqft_living  sqft_lot  \\\n",
       "0      7129300520  2014  221900.0         3       1.00         1180      5650   \n",
       "1      6414100192  2014  538000.0         3       2.25         2570      7242   \n",
       "2      5631500400  2015  180000.0         2       1.00          770     10000   \n",
       "3      2487200875  2014  604000.0         4       3.00         1960      5000   \n",
       "4      1954400510  2015  510000.0         3       2.00         1680      8080   \n",
       "...           ...   ...       ...       ...        ...          ...       ...   \n",
       "21608   263000018  2014  360000.0         3       2.50         1530      1131   \n",
       "21609  6600060120  2015  400000.0         4       2.50         2310      5813   \n",
       "21610  1523300141  2014  402101.0         2       0.75         1020      1350   \n",
       "21611   291310100  2015  400000.0         3       2.50         1600      2388   \n",
       "21612  1523300157  2014  325000.0         2       0.75         1020      1076   \n",
       "\n",
       "       floors  waterfront  view  ...  grade  sqft_above  sqft_basement  \\\n",
       "0         1.0           0     0  ...      7        1180              0   \n",
       "1         2.0           0     0  ...      7        2170            400   \n",
       "2         1.0           0     0  ...      6         770              0   \n",
       "3         1.0           0     0  ...      7        1050            910   \n",
       "4         1.0           0     0  ...      8        1680              0   \n",
       "...       ...         ...   ...  ...    ...         ...            ...   \n",
       "21608     3.0           0     0  ...      8        1530              0   \n",
       "21609     2.0           0     0  ...      8        2310              0   \n",
       "21610     2.0           0     0  ...      7        1020              0   \n",
       "21611     2.0           0     0  ...      8        1600              0   \n",
       "21612     2.0           0     0  ...      7        1020              0   \n",
       "\n",
       "       yr_built  yr_renovated  zipcode      lat     long  sqft_living15  \\\n",
       "0          1955             0    98178  47.5112 -122.257           1340   \n",
       "1          1951          1991    98125  47.7210 -122.319           1690   \n",
       "2          1933             0    98028  47.7379 -122.233           2720   \n",
       "3          1965             0    98136  47.5208 -122.393           1360   \n",
       "4          1987             0    98074  47.6168 -122.045           1800   \n",
       "...         ...           ...      ...      ...      ...            ...   \n",
       "21608      2009             0    98103  47.6993 -122.346           1530   \n",
       "21609      2014             0    98146  47.5107 -122.362           1830   \n",
       "21610      2009             0    98144  47.5944 -122.299           1020   \n",
       "21611      2004             0    98027  47.5345 -122.069           1410   \n",
       "21612      2008             0    98144  47.5941 -122.299           1020   \n",
       "\n",
       "       sqft_lot15  \n",
       "0            5650  \n",
       "1            7639  \n",
       "2            8062  \n",
       "3            5000  \n",
       "4            7503  \n",
       "...           ...  \n",
       "21608        1509  \n",
       "21609        7200  \n",
       "21610        2007  \n",
       "21611        1287  \n",
       "21612        1357  \n",
       "\n",
       "[21613 rows x 21 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_regression = pd.read_csv(\"../data/kc_house_data.csv\")\n",
    "data_regression[\"date\"]=data_regression[\"date\"].str[:4]\n",
    "data_regression[\"date\"]=pd.to_numeric(data_regression[\"date\"])\n",
    "y = data_regression[\"price\"]\n",
    "X = data_regression.drop([\"price\"], axis = 1)\n",
    "data_regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cd5826cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((18371, 20), (18371,), (3242, 20), (3242,))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15)\n",
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a700b1d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "X_reg_train = scaler.transform(X_train)\n",
    "X_reg_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "45db2de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "undersampler = RandomUnderSampler()\n",
    "X_reg_train, y_reg_train = undersampler.fit_resample(X_reg_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "425f278e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_regression = tf.keras.Sequential(\n",
    "    [\n",
    "        tf.keras.layers.Dense(64, activation=\"relu\", input_shape=(20,)),\n",
    "        tf.keras.layers.Dense(32, activation=\"relu\"),\n",
    "        tf.keras.layers.Dropout(0.2),\n",
    "        tf.keras.layers.Dense(16, activation=\"relu\"),\n",
    "        tf.keras.layers.Dropout(0.1),\n",
    "        tf.keras.layers.Dense(8, activation=\"relu\"),\n",
    "        tf.keras.layers.Dropout(0.05),\n",
    "        tf.keras.layers.Dense(1, activation=\"linear\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "675e16a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 64)                1344      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 32)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 16)                528       \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 16)                0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 8)                 136       \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 8)                 0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,097\n",
      "Trainable params: 4,097\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_regression.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "13d92765",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_regression.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.005), loss=\"mse\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4642d2c0",
   "metadata": {},
   "source": [
    "Другие оптимизаторы, доступные в TensorFlow Keras, это: SGD, RMSprop, Adagrad, Adadelta, Adamax, Nadam, Ftrl.\n",
    "\n",
    "В данном случае, функция ошибки ('loss') установлена на 'mse', что означает mean squared error (среднеквадратичную ошибку). Также в TensorFlow Keras доступны и другие функции ошибки, такие как mean absolute error ('mae'), mean absolute percentage error ('mape'), mean squared logarithmic error ('msle') и другие. Они используются в зависимости от типа задачи и цели обучения модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "c64ee10f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n",
      "113/113 [==============================] - 1s 946us/step - loss: 729074761728.0000\n",
      "Epoch 2/80\n",
      "113/113 [==============================] - 0s 902us/step - loss: 197991383040.0000\n",
      "Epoch 3/80\n",
      "113/113 [==============================] - 0s 911us/step - loss: 126295064576.0000\n",
      "Epoch 4/80\n",
      "113/113 [==============================] - 0s 929us/step - loss: 107878588416.0000\n",
      "Epoch 5/80\n",
      "113/113 [==============================] - 0s 964us/step - loss: 96910860288.0000\n",
      "Epoch 6/80\n",
      "113/113 [==============================] - 0s 893us/step - loss: 102168150016.0000\n",
      "Epoch 7/80\n",
      "113/113 [==============================] - 0s 893us/step - loss: 92864823296.0000\n",
      "Epoch 8/80\n",
      "113/113 [==============================] - 0s 875us/step - loss: 87980736512.0000\n",
      "Epoch 9/80\n",
      "113/113 [==============================] - 0s 875us/step - loss: 80162570240.0000\n",
      "Epoch 10/80\n",
      "113/113 [==============================] - 0s 866us/step - loss: 84027998208.0000\n",
      "Epoch 11/80\n",
      "113/113 [==============================] - 0s 866us/step - loss: 89860079616.0000\n",
      "Epoch 12/80\n",
      "113/113 [==============================] - 0s 893us/step - loss: 86784475136.0000\n",
      "Epoch 13/80\n",
      "113/113 [==============================] - 0s 884us/step - loss: 81106329600.0000\n",
      "Epoch 14/80\n",
      "113/113 [==============================] - 0s 893us/step - loss: 81588117504.0000\n",
      "Epoch 15/80\n",
      "113/113 [==============================] - 0s 920us/step - loss: 85553217536.0000\n",
      "Epoch 16/80\n",
      "113/113 [==============================] - 0s 884us/step - loss: 90496843776.0000\n",
      "Epoch 17/80\n",
      "113/113 [==============================] - 0s 866us/step - loss: 81488207872.0000\n",
      "Epoch 18/80\n",
      "113/113 [==============================] - 0s 875us/step - loss: 80577060864.0000\n",
      "Epoch 19/80\n",
      "113/113 [==============================] - 0s 866us/step - loss: 76844933120.0000\n",
      "Epoch 20/80\n",
      "113/113 [==============================] - 0s 866us/step - loss: 79015739392.0000\n",
      "Epoch 21/80\n",
      "113/113 [==============================] - 0s 875us/step - loss: 76527370240.0000\n",
      "Epoch 22/80\n",
      "113/113 [==============================] - 0s 893us/step - loss: 81323507712.0000\n",
      "Epoch 23/80\n",
      "113/113 [==============================] - 0s 884us/step - loss: 84667359232.0000\n",
      "Epoch 24/80\n",
      "113/113 [==============================] - 0s 902us/step - loss: 71542988800.0000\n",
      "Epoch 25/80\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 72044617728.0000\n",
      "Epoch 26/80\n",
      "113/113 [==============================] - 0s 964us/step - loss: 77031227392.0000\n",
      "Epoch 27/80\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 71694417920.0000\n",
      "Epoch 28/80\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 85276426240.0000\n",
      "Epoch 29/80\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 77874192384.0000\n",
      "Epoch 30/80\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 77523517440.0000\n",
      "Epoch 31/80\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 77358252032.0000\n",
      "Epoch 32/80\n",
      "113/113 [==============================] - 0s 893us/step - loss: 71703855104.0000\n",
      "Epoch 33/80\n",
      "113/113 [==============================] - 0s 893us/step - loss: 79871049728.0000\n",
      "Epoch 34/80\n",
      "113/113 [==============================] - 0s 866us/step - loss: 75964252160.0000\n",
      "Epoch 35/80\n",
      "113/113 [==============================] - 0s 866us/step - loss: 74109870080.0000\n",
      "Epoch 36/80\n",
      "113/113 [==============================] - 0s 893us/step - loss: 75707416576.0000\n",
      "Epoch 37/80\n",
      "113/113 [==============================] - 0s 902us/step - loss: 74246111232.0000\n",
      "Epoch 38/80\n",
      "113/113 [==============================] - 0s 884us/step - loss: 70895714304.0000\n",
      "Epoch 39/80\n",
      "113/113 [==============================] - 0s 884us/step - loss: 71433805824.0000\n",
      "Epoch 40/80\n",
      "113/113 [==============================] - 0s 884us/step - loss: 75800608768.0000\n",
      "Epoch 41/80\n",
      "113/113 [==============================] - 0s 893us/step - loss: 74071384064.0000\n",
      "Epoch 42/80\n",
      "113/113 [==============================] - 0s 902us/step - loss: 67377512448.0000\n",
      "Epoch 43/80\n",
      "113/113 [==============================] - 0s 902us/step - loss: 71604477952.0000\n",
      "Epoch 44/80\n",
      "113/113 [==============================] - 0s 982us/step - loss: 72841330688.0000\n",
      "Epoch 45/80\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 76233056256.0000\n",
      "Epoch 46/80\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 73228460032.0000\n",
      "Epoch 47/80\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 69891645440.0000\n",
      "Epoch 48/80\n",
      "113/113 [==============================] - 0s 973us/step - loss: 71658995712.0000\n",
      "Epoch 49/80\n",
      "113/113 [==============================] - 0s 920us/step - loss: 72920702976.0000\n",
      "Epoch 50/80\n",
      "113/113 [==============================] - 0s 893us/step - loss: 77349609472.0000\n",
      "Epoch 51/80\n",
      "113/113 [==============================] - 0s 911us/step - loss: 69830615040.0000\n",
      "Epoch 52/80\n",
      "113/113 [==============================] - 0s 893us/step - loss: 72971304960.0000\n",
      "Epoch 53/80\n",
      "113/113 [==============================] - 0s 902us/step - loss: 67974651904.0000\n",
      "Epoch 54/80\n",
      "113/113 [==============================] - 0s 866us/step - loss: 74925981696.0000\n",
      "Epoch 55/80\n",
      "113/113 [==============================] - 0s 866us/step - loss: 74914627584.0000\n",
      "Epoch 56/80\n",
      "113/113 [==============================] - 0s 857us/step - loss: 69174730752.0000\n",
      "Epoch 57/80\n",
      "113/113 [==============================] - 0s 857us/step - loss: 77455810560.0000\n",
      "Epoch 58/80\n",
      "113/113 [==============================] - 0s 848us/step - loss: 69023866880.0000\n",
      "Epoch 59/80\n",
      "113/113 [==============================] - 0s 875us/step - loss: 69375565824.0000\n",
      "Epoch 60/80\n",
      "113/113 [==============================] - 0s 920us/step - loss: 65956769792.0000\n",
      "Epoch 61/80\n",
      "113/113 [==============================] - 0s 920us/step - loss: 72449851392.0000\n",
      "Epoch 62/80\n",
      "113/113 [==============================] - 0s 876us/step - loss: 67300450304.0000\n",
      "Epoch 63/80\n",
      "113/113 [==============================] - 0s 839us/step - loss: 62573543424.0000\n",
      "Epoch 64/80\n",
      "113/113 [==============================] - 0s 857us/step - loss: 67745959936.0000\n",
      "Epoch 65/80\n",
      "113/113 [==============================] - 0s 955us/step - loss: 70486441984.0000\n",
      "Epoch 66/80\n",
      "113/113 [==============================] - 0s 893us/step - loss: 65970323456.0000\n",
      "Epoch 67/80\n",
      "113/113 [==============================] - 0s 884us/step - loss: 62580588544.0000\n",
      "Epoch 68/80\n",
      "113/113 [==============================] - 0s 875us/step - loss: 69708070912.0000\n",
      "Epoch 69/80\n",
      "113/113 [==============================] - 0s 893us/step - loss: 64146440192.0000\n",
      "Epoch 70/80\n",
      "113/113 [==============================] - 0s 946us/step - loss: 67008049152.0000\n",
      "Epoch 71/80\n",
      "113/113 [==============================] - 0s 964us/step - loss: 64563388416.0000\n",
      "Epoch 72/80\n",
      "113/113 [==============================] - 0s 884us/step - loss: 68738285568.0000\n",
      "Epoch 73/80\n",
      "113/113 [==============================] - 0s 848us/step - loss: 64763408384.0000\n",
      "Epoch 74/80\n",
      "113/113 [==============================] - 0s 821us/step - loss: 70249324544.0000\n",
      "Epoch 75/80\n",
      "113/113 [==============================] - 0s 839us/step - loss: 61353037824.0000\n",
      "Epoch 76/80\n",
      "113/113 [==============================] - 0s 866us/step - loss: 67044753408.0000\n",
      "Epoch 77/80\n",
      "113/113 [==============================] - 0s 884us/step - loss: 62892617728.0000\n",
      "Epoch 78/80\n",
      "113/113 [==============================] - 0s 848us/step - loss: 60962562048.0000\n",
      "Epoch 79/80\n",
      "113/113 [==============================] - 0s 857us/step - loss: 67020804096.0000\n",
      "Epoch 80/80\n",
      "113/113 [==============================] - 0s 848us/step - loss: 62611124224.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x26d4410ab60>"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_regression.fit(X_reg_train, y_reg_train, epochs=80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "b3582708",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102/102 [==============================] - 0s 584us/step\n",
      "107339.22433104565\n",
      "102/102 [==============================] - 0s 574us/step\n",
      "30739188311.36287\n",
      "102/102 [==============================] - 0s 574us/step\n",
      "0.7575981264971131\n"
     ]
    }
   ],
   "source": [
    "print(mean_absolute_error(y_test, model_regression.predict(X_reg_test)))\n",
    "print(mean_squared_error(y_test, model_regression.predict(X_reg_test)))\n",
    "print(r2_score(y_test, model_regression.predict(X_reg_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "f772dab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_regression.save('model_regression_neuro.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2e4550f",
   "metadata": {},
   "source": [
    "**КЛАССИФИКАЦИЯ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "462f07b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>distance_from_home</th>\n",
       "      <th>distance_from_last_transaction</th>\n",
       "      <th>ratio_to_median_purchase_price</th>\n",
       "      <th>repeat_retailer</th>\n",
       "      <th>used_chip</th>\n",
       "      <th>used_pin_number</th>\n",
       "      <th>online_order</th>\n",
       "      <th>fraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>57.877857</td>\n",
       "      <td>0.311140</td>\n",
       "      <td>1.945940</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.829943</td>\n",
       "      <td>0.175592</td>\n",
       "      <td>1.294219</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.091079</td>\n",
       "      <td>0.805153</td>\n",
       "      <td>0.427715</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.247564</td>\n",
       "      <td>5.600044</td>\n",
       "      <td>0.362663</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>44.190936</td>\n",
       "      <td>0.566486</td>\n",
       "      <td>2.222767</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999995</th>\n",
       "      <td>2.207101</td>\n",
       "      <td>0.112651</td>\n",
       "      <td>1.626798</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999996</th>\n",
       "      <td>19.872726</td>\n",
       "      <td>2.683904</td>\n",
       "      <td>2.778303</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999997</th>\n",
       "      <td>2.914857</td>\n",
       "      <td>1.472687</td>\n",
       "      <td>0.218075</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999998</th>\n",
       "      <td>4.258729</td>\n",
       "      <td>0.242023</td>\n",
       "      <td>0.475822</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999999</th>\n",
       "      <td>58.108125</td>\n",
       "      <td>0.318110</td>\n",
       "      <td>0.386920</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000000 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        distance_from_home  distance_from_last_transaction  \\\n",
       "0                57.877857                        0.311140   \n",
       "1                10.829943                        0.175592   \n",
       "2                 5.091079                        0.805153   \n",
       "3                 2.247564                        5.600044   \n",
       "4                44.190936                        0.566486   \n",
       "...                    ...                             ...   \n",
       "999995            2.207101                        0.112651   \n",
       "999996           19.872726                        2.683904   \n",
       "999997            2.914857                        1.472687   \n",
       "999998            4.258729                        0.242023   \n",
       "999999           58.108125                        0.318110   \n",
       "\n",
       "        ratio_to_median_purchase_price  repeat_retailer  used_chip  \\\n",
       "0                             1.945940              1.0        1.0   \n",
       "1                             1.294219              1.0        0.0   \n",
       "2                             0.427715              1.0        0.0   \n",
       "3                             0.362663              1.0        1.0   \n",
       "4                             2.222767              1.0        1.0   \n",
       "...                                ...              ...        ...   \n",
       "999995                        1.626798              1.0        1.0   \n",
       "999996                        2.778303              1.0        1.0   \n",
       "999997                        0.218075              1.0        1.0   \n",
       "999998                        0.475822              1.0        0.0   \n",
       "999999                        0.386920              1.0        1.0   \n",
       "\n",
       "        used_pin_number  online_order  fraud  \n",
       "0                   0.0           0.0    0.0  \n",
       "1                   0.0           0.0    0.0  \n",
       "2                   0.0           1.0    0.0  \n",
       "3                   0.0           1.0    0.0  \n",
       "4                   0.0           1.0    0.0  \n",
       "...                 ...           ...    ...  \n",
       "999995              0.0           0.0    0.0  \n",
       "999996              0.0           0.0    0.0  \n",
       "999997              0.0           1.0    0.0  \n",
       "999998              0.0           1.0    0.0  \n",
       "999999              0.0           1.0    0.0  \n",
       "\n",
       "[1000000 rows x 8 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_classification = pd.read_csv(\"../data/card_transdata.csv\")\n",
    "x = data_classification.drop([\"fraud\"], axis = 1)\n",
    "Y = data_classification[\"fraud\"]\n",
    "data_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9131b89e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((850000, 7), (850000,), (150000, 7), (150000,))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_clf_train, X_clf_test, y_clf_train, y_clf_test = train_test_split(x, Y, test_size=0.15)\n",
    "X_clf_train.shape, y_clf_train.shape, X_clf_test.shape, y_clf_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6d910271",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((148686, 7), (148686,), (150000, 7), (150000,))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "undersample = RandomUnderSampler()\n",
    "x_under, y_under = undersample.fit_resample(X_clf_train, y_clf_train)\n",
    "x_under.shape, y_under.shape, X_clf_test.shape, y_clf_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "cce2d7a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_classification = tf.keras.Sequential(\n",
    "    [\n",
    "        tf.keras.layers.Dense(64, activation=\"relu\", input_shape=(7,)),\n",
    "        tf.keras.layers.Dense(128, activation=\"relu\"),\n",
    "        tf.keras.layers.Dropout(0.05),\n",
    "        tf.keras.layers.Dense(32, activation=\"relu\"),\n",
    "        tf.keras.layers.Dense(16, activation=\"relu\"),\n",
    "        tf.keras.layers.Dropout(0.05),\n",
    "        tf.keras.layers.Dense(1, activation=\"sigmoid\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "625d898b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1b101932560>"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_classification.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), loss=\"binary_crossentropy\")\n",
    "model_classification.fit(x_under, y_under, epochs=25, verbose=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "4416b7c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.around(model_classification.predict(X_clf_test, verbose=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "4a5b64fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.99      0.99    136922\n",
      "         1.0       0.90      1.00      0.95     13078\n",
      "\n",
      "    accuracy                           0.99    150000\n",
      "   macro avg       0.95      0.99      0.97    150000\n",
      "weighted avg       0.99      0.99      0.99    150000\n",
      "\n",
      "[[135475   1447]\n",
      " [     8  13070]]\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_clf_test, y_pred))\n",
    "print(confusion_matrix(y_clf_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "d0c685e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_classification.save('model_classification_neuro.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d5a284d",
   "metadata": {},
   "source": [
    "**Собственная реализация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3ffb7482",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sympyNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "  Downloading sympy-1.12-py3-none-any.whl (5.7 MB)\n",
      "     ---------------------------------------- 5.7/5.7 MB 5.1 MB/s eta 0:00:00\n",
      "Collecting mpmath>=0.19\n",
      "  Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "     -------------------------------------- 536.2/536.2 KB 8.5 MB/s eta 0:00:00\n",
      "Installing collected packages: mpmath, sympy\n",
      "Successfully installed mpmath-1.3.0 sympy-1.12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 22.0.4; however, version 23.1.2 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\Aron\\Desktop\\Учеба\\4 семестр\\Машинное обучение\\Jupiter nouts\\venv\\Scripts\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "pip install sympy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "21f1f810",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numdifftools as nd\n",
    "class NeuroLayer:\n",
    "\n",
    "    def __init__(self, numOfNeurons: int, activation: str) -> None:\n",
    "        allowedActivation = ['sigmoid', 'tanh', 'relu', 'linear']\n",
    "        self.n = numOfNeurons\n",
    "        self.connectedToPrevious = np.array([])\n",
    "        if activation in allowedActivation:\n",
    "            if activation == 'sigmoid':\n",
    "                self.af = self.sigmoid\n",
    "            elif activation == 'tanh':\n",
    "                self.af = self.tanh\n",
    "            elif activation == 'relu':\n",
    "                self.af = self.relu\n",
    "            elif activation == 'linear':\n",
    "                self.af = self.linear\n",
    "\n",
    "    def sigmoid(self, x: np.ndarray) -> np.ndarray:\n",
    "        return 1/(1+np.exp(-1 * x)).astype(\"float64\")\n",
    "    \n",
    "    def tanh(self, x: np.ndarray) -> np.ndarray:\n",
    "        return np.tanh(x)\n",
    "    \n",
    "    def relu(self, x: np.ndarray) -> np.ndarray:\n",
    "        return np.maximum(x, 0)\n",
    "    \n",
    "    def linear(self, x: np.ndarray) -> np.ndarray:\n",
    "        return x\n",
    "    \n",
    "    def forward(self, x: np.ndarray) -> np.ndarray:\n",
    "        self.x = x\n",
    "        temp = np.dot(self.connectedToPrevious, self.x) + self.b\n",
    "        self.a = self.af(temp)\n",
    "        self.ga = nd.Derivative(self.af)(temp)\n",
    "        return self.a\n",
    "    \n",
    "    def fast_forward(self, x: np.ndarray) -> np.ndarray:\n",
    "        return self.af(np.dot(self.connectedToPrevious, x) + self.b)\n",
    "    \n",
    "    def backward(self, gr: np.ndarray, m, lr) -> np.ndarray:\n",
    "        buf = np.multiply(self.ga.T, np.dot(gr, m))\n",
    "        self.b -= lr * buf.T\n",
    "        self.connectedToPrevious -= lr*np.dot(self.x, buf).T\n",
    "        return buf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f9222d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuroNet:\n",
    "    def __init__(self, sequence: list, input_shape: tuple) -> None:\n",
    "        self.layers = sequence\n",
    "        buf = np.random.normal(0, 1, (self.layers[0].n, input_shape[0]))\n",
    "        self.matrices = [buf]\n",
    "        self.layers[0].connectedToPrevious = buf\n",
    "        self.layers[0].b = np.random.normal(0, 1, (self.layers[0].n, 1))\n",
    "        \n",
    "    def __MSE(self, yp, yr):\n",
    "        return np.mean((yr-yp)**2)\n",
    "        \n",
    "    def compile(self, loss: str) -> None:\n",
    "        for i in range(len(self.layers) - 1):\n",
    "            buf = np.random.normal(0, 1, (self.layers[i+1].n, self.layers[i].n))\n",
    "            self.matrices.append(buf)\n",
    "            self.layers[i+1].connectedToPrevious = buf\n",
    "            self.layers[i+1].b = np.random.normal(0, 1, (self.layers[i+1].n, 1))\n",
    "            \n",
    "    def __max_batches(self, n: int) -> int:\n",
    "        i = n // 2\n",
    "        m = 20 if n < 100 else 250\n",
    "        while i > m:\n",
    "            if n % i == 0:\n",
    "                return i\n",
    "            i -= 1\n",
    "        return i\n",
    "            \n",
    "    def fit(self, X:pd.DataFrame, y:pd.Series, e:int, rate: float = 0.01) -> np.ndarray:\n",
    "        X = X.to_numpy()\n",
    "        for i in range(e):\n",
    "            print(f\"Initializing epoch {i+1} of {e}\")\n",
    "            \n",
    "            nbatches = self.__max_batches(len(X))\n",
    "            \n",
    "            batchSize = len(X) // nbatches\n",
    "            \n",
    "            start = 0\n",
    "            \n",
    "            totalp = []\n",
    "            \n",
    "            for i in range(batchSize, nbatches, batchSize):\n",
    "                batch = X[start:i]\n",
    "                \n",
    "                for ind, ob in enumerate(batch):\n",
    "                    ob = ob[np.newaxis, :].T\n",
    "                    for layer in self.layers:\n",
    "                        ob = layer.forward(ob)\n",
    "                    \n",
    "                    pred = ob\n",
    "                    totalp.append(pred.flatten()[0])\n",
    "                    \n",
    "                    gr = nd.Gradient(self.__MSE)(pred, y.values[start:i][ind])\n",
    "                    \n",
    "                    m = 1\n",
    "                    \n",
    "                    for layer in self.layers[::-1]:\n",
    "                        gr = layer.backward(gr, m, rate)\n",
    "                        m = layer.connectedToPrevious\n",
    "                \n",
    "                start += batchSize\n",
    "        self.matrices = [layer.connectedToPrevious for layer in self.layers]\n",
    "                \n",
    "    def predict(self, X: pd.DataFrame) -> np.ndarray:\n",
    "        X = X.to_numpy()\n",
    "        pred = []\n",
    "        for ind, ob in enumerate(X):\n",
    "            print(f\"{ind}/{X.shape[0]}\", end='\\r')\n",
    "            ob = ob[np.newaxis, :].T\n",
    "            for layer in self.layers:\n",
    "                ob = layer.fast_forward(ob)\n",
    "            pred.append(ob.flatten()[0])\n",
    "            \n",
    "        return np.array(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ba15cc1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((148686, 7), (148686,), (150000, 7), (150000,))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "undersample1 = RandomUnderSampler()\n",
    "x_under1, y_under1 = undersample1.fit_resample(x_under, y_under)\n",
    "x_under1.shape, y_under1.shape, X_clf_test.shape, y_clf_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "39ea0b9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing epoch 1 of 5\n",
      "Initializing epoch 2 of 5\n",
      "Initializing epoch 3 of 5\n",
      "Initializing epoch 4 of 5\n",
      "Initializing epoch 5 of 5\n",
      "3241/3242\r"
     ]
    }
   ],
   "source": [
    "layer1 = NeuroLayer(16, 'relu')\n",
    "layer2 = NeuroLayer(8, 'relu')\n",
    "layer3 = NeuroLayer(4, 'relu')\n",
    "layer4 = NeuroLayer(1, 'linear')\n",
    "\n",
    "layer1.connectedToPrevious = np.random.normal(0, 1, (16, 20))\n",
    "layer2.connectedToPrevious = np.random.normal(0, 1, (8, 16))\n",
    "layer3.connectedToPrevious = np.random.normal(0, 1, (4, 8))\n",
    "layer4.connectedToPrevious = np.random.normal(0, 1, (1, 4))\n",
    "\n",
    "net = NeuroNet([layer1, layer2, layer3, layer4], (20,))\n",
    "\n",
    "net.compile('MSE')\n",
    "net.fit(pd.DataFrame(X_reg_train), y_reg_train, 5, 0.0001)\n",
    "pred = net.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "77053d0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.44481656e+19 1.00607572e+19 9.71814152e+18 ... 1.15524974e+19\n",
      " 1.31605643e+19 1.20492395e+19]\n"
     ]
    }
   ],
   "source": [
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "842e9611",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing epoch 1 of 40\n",
      "Initializing epoch 2 of 40\n",
      "Initializing epoch 3 of 40\n",
      "Initializing epoch 4 of 40\n",
      "Initializing epoch 5 of 40\n",
      "Initializing epoch 6 of 40\n",
      "Initializing epoch 7 of 40\n",
      "Initializing epoch 8 of 40\n",
      "Initializing epoch 9 of 40\n",
      "Initializing epoch 10 of 40\n",
      "Initializing epoch 11 of 40\n",
      "Initializing epoch 12 of 40\n",
      "Initializing epoch 13 of 40\n",
      "Initializing epoch 14 of 40\n",
      "Initializing epoch 15 of 40\n",
      "Initializing epoch 16 of 40\n",
      "Initializing epoch 17 of 40\n",
      "Initializing epoch 18 of 40\n",
      "Initializing epoch 19 of 40\n",
      "Initializing epoch 20 of 40\n",
      "Initializing epoch 21 of 40\n",
      "Initializing epoch 22 of 40\n",
      "Initializing epoch 23 of 40\n",
      "Initializing epoch 24 of 40\n",
      "Initializing epoch 25 of 40\n",
      "Initializing epoch 26 of 40\n",
      "Initializing epoch 27 of 40\n",
      "Initializing epoch 28 of 40\n",
      "Initializing epoch 29 of 40\n",
      "Initializing epoch 30 of 40\n",
      "Initializing epoch 31 of 40\n",
      "Initializing epoch 32 of 40\n",
      "Initializing epoch 33 of 40\n",
      "Initializing epoch 34 of 40\n",
      "Initializing epoch 35 of 40\n",
      "Initializing epoch 36 of 40\n",
      "Initializing epoch 37 of 40\n",
      "Initializing epoch 38 of 40\n",
      "Initializing epoch 39 of 40\n",
      "Initializing epoch 40 of 40\n",
      "3241/3242\r"
     ]
    }
   ],
   "source": [
    "layer11 = NeuroLayer(64, 'relu')\n",
    "layer22 = NeuroLayer(32, 'relu')\n",
    "layer33 = NeuroLayer(16, 'relu')\n",
    "layer44 = NeuroLayer(1, 'linear')\n",
    "\n",
    "layer11.connectedToPrevious = np.random.normal(0, 1, (64, 20))\n",
    "layer22.connectedToPrevious = np.random.normal(0, 1, (32, 64))\n",
    "layer33.connectedToPrevious = np.random.normal(0, 1, (16, 32))\n",
    "layer44.connectedToPrevious = np.random.normal(0, 1, (1, 16))\n",
    "\n",
    "net1 = NeuroNet([layer11, layer22, layer33, layer44], (20,))\n",
    "\n",
    "net1.compile('MSE')\n",
    "net1.fit(pd.DataFrame(X_reg_train), y_reg_train, 40, 0.0001)\n",
    "pred1 = net1.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "ecd49f16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.31816228e+23 2.35897122e+23 2.36221169e+23 ... 2.34488522e+23\n",
      " 2.33004503e+23 2.34030104e+23]\n"
     ]
    }
   ],
   "source": [
    "print(pred1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a35c7213",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
