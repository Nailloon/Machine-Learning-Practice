{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5351e5d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.manifold import TSNE, Isomap\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b3d8f26a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(X, y):\n",
    "  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, shuffle=False)\n",
    "  bag = BaggingRegressor().fit(X_train, y_train)\n",
    "  print(bag.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c536b333",
   "metadata": {},
   "source": [
    "Регрессия и все с нею связанное"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3cd014e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>price</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>sqft_living</th>\n",
       "      <th>sqft_lot</th>\n",
       "      <th>floors</th>\n",
       "      <th>waterfront</th>\n",
       "      <th>view</th>\n",
       "      <th>...</th>\n",
       "      <th>grade</th>\n",
       "      <th>sqft_above</th>\n",
       "      <th>sqft_basement</th>\n",
       "      <th>yr_built</th>\n",
       "      <th>yr_renovated</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>sqft_living15</th>\n",
       "      <th>sqft_lot15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7129300520</td>\n",
       "      <td>2014</td>\n",
       "      <td>221900.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1180</td>\n",
       "      <td>5650</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>1180</td>\n",
       "      <td>0</td>\n",
       "      <td>1955</td>\n",
       "      <td>0</td>\n",
       "      <td>98178</td>\n",
       "      <td>47.5112</td>\n",
       "      <td>-122.257</td>\n",
       "      <td>1340</td>\n",
       "      <td>5650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6414100192</td>\n",
       "      <td>2014</td>\n",
       "      <td>538000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.25</td>\n",
       "      <td>2570</td>\n",
       "      <td>7242</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>2170</td>\n",
       "      <td>400</td>\n",
       "      <td>1951</td>\n",
       "      <td>1991</td>\n",
       "      <td>98125</td>\n",
       "      <td>47.7210</td>\n",
       "      <td>-122.319</td>\n",
       "      <td>1690</td>\n",
       "      <td>7639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5631500400</td>\n",
       "      <td>2015</td>\n",
       "      <td>180000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.00</td>\n",
       "      <td>770</td>\n",
       "      <td>10000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>770</td>\n",
       "      <td>0</td>\n",
       "      <td>1933</td>\n",
       "      <td>0</td>\n",
       "      <td>98028</td>\n",
       "      <td>47.7379</td>\n",
       "      <td>-122.233</td>\n",
       "      <td>2720</td>\n",
       "      <td>8062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2487200875</td>\n",
       "      <td>2014</td>\n",
       "      <td>604000.0</td>\n",
       "      <td>4</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1960</td>\n",
       "      <td>5000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>1050</td>\n",
       "      <td>910</td>\n",
       "      <td>1965</td>\n",
       "      <td>0</td>\n",
       "      <td>98136</td>\n",
       "      <td>47.5208</td>\n",
       "      <td>-122.393</td>\n",
       "      <td>1360</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1954400510</td>\n",
       "      <td>2015</td>\n",
       "      <td>510000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1680</td>\n",
       "      <td>8080</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>1680</td>\n",
       "      <td>0</td>\n",
       "      <td>1987</td>\n",
       "      <td>0</td>\n",
       "      <td>98074</td>\n",
       "      <td>47.6168</td>\n",
       "      <td>-122.045</td>\n",
       "      <td>1800</td>\n",
       "      <td>7503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21608</th>\n",
       "      <td>263000018</td>\n",
       "      <td>2014</td>\n",
       "      <td>360000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.50</td>\n",
       "      <td>1530</td>\n",
       "      <td>1131</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>1530</td>\n",
       "      <td>0</td>\n",
       "      <td>2009</td>\n",
       "      <td>0</td>\n",
       "      <td>98103</td>\n",
       "      <td>47.6993</td>\n",
       "      <td>-122.346</td>\n",
       "      <td>1530</td>\n",
       "      <td>1509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21609</th>\n",
       "      <td>6600060120</td>\n",
       "      <td>2015</td>\n",
       "      <td>400000.0</td>\n",
       "      <td>4</td>\n",
       "      <td>2.50</td>\n",
       "      <td>2310</td>\n",
       "      <td>5813</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>2310</td>\n",
       "      <td>0</td>\n",
       "      <td>2014</td>\n",
       "      <td>0</td>\n",
       "      <td>98146</td>\n",
       "      <td>47.5107</td>\n",
       "      <td>-122.362</td>\n",
       "      <td>1830</td>\n",
       "      <td>7200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21610</th>\n",
       "      <td>1523300141</td>\n",
       "      <td>2014</td>\n",
       "      <td>402101.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1020</td>\n",
       "      <td>1350</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>1020</td>\n",
       "      <td>0</td>\n",
       "      <td>2009</td>\n",
       "      <td>0</td>\n",
       "      <td>98144</td>\n",
       "      <td>47.5944</td>\n",
       "      <td>-122.299</td>\n",
       "      <td>1020</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21611</th>\n",
       "      <td>291310100</td>\n",
       "      <td>2015</td>\n",
       "      <td>400000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.50</td>\n",
       "      <td>1600</td>\n",
       "      <td>2388</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>1600</td>\n",
       "      <td>0</td>\n",
       "      <td>2004</td>\n",
       "      <td>0</td>\n",
       "      <td>98027</td>\n",
       "      <td>47.5345</td>\n",
       "      <td>-122.069</td>\n",
       "      <td>1410</td>\n",
       "      <td>1287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21612</th>\n",
       "      <td>1523300157</td>\n",
       "      <td>2014</td>\n",
       "      <td>325000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1020</td>\n",
       "      <td>1076</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>1020</td>\n",
       "      <td>0</td>\n",
       "      <td>2008</td>\n",
       "      <td>0</td>\n",
       "      <td>98144</td>\n",
       "      <td>47.5941</td>\n",
       "      <td>-122.299</td>\n",
       "      <td>1020</td>\n",
       "      <td>1357</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21613 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               id  date     price  bedrooms  bathrooms  sqft_living  sqft_lot  \\\n",
       "0      7129300520  2014  221900.0         3       1.00         1180      5650   \n",
       "1      6414100192  2014  538000.0         3       2.25         2570      7242   \n",
       "2      5631500400  2015  180000.0         2       1.00          770     10000   \n",
       "3      2487200875  2014  604000.0         4       3.00         1960      5000   \n",
       "4      1954400510  2015  510000.0         3       2.00         1680      8080   \n",
       "...           ...   ...       ...       ...        ...          ...       ...   \n",
       "21608   263000018  2014  360000.0         3       2.50         1530      1131   \n",
       "21609  6600060120  2015  400000.0         4       2.50         2310      5813   \n",
       "21610  1523300141  2014  402101.0         2       0.75         1020      1350   \n",
       "21611   291310100  2015  400000.0         3       2.50         1600      2388   \n",
       "21612  1523300157  2014  325000.0         2       0.75         1020      1076   \n",
       "\n",
       "       floors  waterfront  view  ...  grade  sqft_above  sqft_basement  \\\n",
       "0         1.0           0     0  ...      7        1180              0   \n",
       "1         2.0           0     0  ...      7        2170            400   \n",
       "2         1.0           0     0  ...      6         770              0   \n",
       "3         1.0           0     0  ...      7        1050            910   \n",
       "4         1.0           0     0  ...      8        1680              0   \n",
       "...       ...         ...   ...  ...    ...         ...            ...   \n",
       "21608     3.0           0     0  ...      8        1530              0   \n",
       "21609     2.0           0     0  ...      8        2310              0   \n",
       "21610     2.0           0     0  ...      7        1020              0   \n",
       "21611     2.0           0     0  ...      8        1600              0   \n",
       "21612     2.0           0     0  ...      7        1020              0   \n",
       "\n",
       "       yr_built  yr_renovated  zipcode      lat     long  sqft_living15  \\\n",
       "0          1955             0    98178  47.5112 -122.257           1340   \n",
       "1          1951          1991    98125  47.7210 -122.319           1690   \n",
       "2          1933             0    98028  47.7379 -122.233           2720   \n",
       "3          1965             0    98136  47.5208 -122.393           1360   \n",
       "4          1987             0    98074  47.6168 -122.045           1800   \n",
       "...         ...           ...      ...      ...      ...            ...   \n",
       "21608      2009             0    98103  47.6993 -122.346           1530   \n",
       "21609      2014             0    98146  47.5107 -122.362           1830   \n",
       "21610      2009             0    98144  47.5944 -122.299           1020   \n",
       "21611      2004             0    98027  47.5345 -122.069           1410   \n",
       "21612      2008             0    98144  47.5941 -122.299           1020   \n",
       "\n",
       "       sqft_lot15  \n",
       "0            5650  \n",
       "1            7639  \n",
       "2            8062  \n",
       "3            5000  \n",
       "4            7503  \n",
       "...           ...  \n",
       "21608        1509  \n",
       "21609        7200  \n",
       "21610        2007  \n",
       "21611        1287  \n",
       "21612        1357  \n",
       "\n",
       "[21613 rows x 21 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_regression = pd.read_csv(\"../data/kc_house_data.csv\")\n",
    "data_regression[\"date\"]=data_regression[\"date\"].str[:4]\n",
    "data_regression[\"date\"]=pd.to_numeric(data_regression[\"date\"])\n",
    "y = data_regression[\"price\"]\n",
    "X = data_regression.drop([\"price\"], axis = 1)\n",
    "data_regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3324c6e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8553909605448788\n"
     ]
    }
   ],
   "source": [
    "test(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "675e5db0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8675212820986693\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "X_scaled = pd.DataFrame(X_scaled, columns=X.columns)\n",
    "test(X_scaled, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b332568e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>sqft_living</th>\n",
       "      <th>sqft_lot</th>\n",
       "      <th>floors</th>\n",
       "      <th>waterfront</th>\n",
       "      <th>view</th>\n",
       "      <th>condition</th>\n",
       "      <th>grade</th>\n",
       "      <th>sqft_above</th>\n",
       "      <th>sqft_basement</th>\n",
       "      <th>yr_built</th>\n",
       "      <th>yr_renovated</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>sqft_living15</th>\n",
       "      <th>sqft_lot15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2.161300e+04</td>\n",
       "      <td>21613.000000</td>\n",
       "      <td>21613.000000</td>\n",
       "      <td>21613.000000</td>\n",
       "      <td>21613.000000</td>\n",
       "      <td>2.161300e+04</td>\n",
       "      <td>21613.000000</td>\n",
       "      <td>21613.000000</td>\n",
       "      <td>21613.000000</td>\n",
       "      <td>21613.000000</td>\n",
       "      <td>21613.000000</td>\n",
       "      <td>21613.000000</td>\n",
       "      <td>21613.000000</td>\n",
       "      <td>21613.000000</td>\n",
       "      <td>21613.000000</td>\n",
       "      <td>21613.000000</td>\n",
       "      <td>21613.000000</td>\n",
       "      <td>21613.000000</td>\n",
       "      <td>21613.000000</td>\n",
       "      <td>21613.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4.580302e+09</td>\n",
       "      <td>2014.322954</td>\n",
       "      <td>3.370842</td>\n",
       "      <td>2.114757</td>\n",
       "      <td>2079.899736</td>\n",
       "      <td>1.510697e+04</td>\n",
       "      <td>1.494309</td>\n",
       "      <td>0.007542</td>\n",
       "      <td>0.234303</td>\n",
       "      <td>3.409430</td>\n",
       "      <td>7.656873</td>\n",
       "      <td>1788.390691</td>\n",
       "      <td>291.509045</td>\n",
       "      <td>1971.005136</td>\n",
       "      <td>84.402258</td>\n",
       "      <td>98077.939805</td>\n",
       "      <td>47.560053</td>\n",
       "      <td>-122.213896</td>\n",
       "      <td>1986.552492</td>\n",
       "      <td>12768.455652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.876566e+09</td>\n",
       "      <td>0.467616</td>\n",
       "      <td>0.930062</td>\n",
       "      <td>0.770163</td>\n",
       "      <td>918.440897</td>\n",
       "      <td>4.142051e+04</td>\n",
       "      <td>0.539989</td>\n",
       "      <td>0.086517</td>\n",
       "      <td>0.766318</td>\n",
       "      <td>0.650743</td>\n",
       "      <td>1.175459</td>\n",
       "      <td>828.090978</td>\n",
       "      <td>442.575043</td>\n",
       "      <td>29.373411</td>\n",
       "      <td>401.679240</td>\n",
       "      <td>53.505026</td>\n",
       "      <td>0.138564</td>\n",
       "      <td>0.140828</td>\n",
       "      <td>685.391304</td>\n",
       "      <td>27304.179631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000102e+06</td>\n",
       "      <td>2014.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>290.000000</td>\n",
       "      <td>5.200000e+02</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>290.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1900.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>98001.000000</td>\n",
       "      <td>47.155900</td>\n",
       "      <td>-122.519000</td>\n",
       "      <td>399.000000</td>\n",
       "      <td>651.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.123049e+09</td>\n",
       "      <td>2014.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.750000</td>\n",
       "      <td>1427.000000</td>\n",
       "      <td>5.040000e+03</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1190.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1951.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>98033.000000</td>\n",
       "      <td>47.471000</td>\n",
       "      <td>-122.328000</td>\n",
       "      <td>1490.000000</td>\n",
       "      <td>5100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.904930e+09</td>\n",
       "      <td>2014.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.250000</td>\n",
       "      <td>1910.000000</td>\n",
       "      <td>7.618000e+03</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1560.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1975.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>98065.000000</td>\n",
       "      <td>47.571800</td>\n",
       "      <td>-122.230000</td>\n",
       "      <td>1840.000000</td>\n",
       "      <td>7620.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7.308900e+09</td>\n",
       "      <td>2015.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>2550.000000</td>\n",
       "      <td>1.068800e+04</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>2210.000000</td>\n",
       "      <td>560.000000</td>\n",
       "      <td>1997.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>98118.000000</td>\n",
       "      <td>47.678000</td>\n",
       "      <td>-122.125000</td>\n",
       "      <td>2360.000000</td>\n",
       "      <td>10083.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9.900000e+09</td>\n",
       "      <td>2015.000000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>13540.000000</td>\n",
       "      <td>1.651359e+06</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>9410.000000</td>\n",
       "      <td>4820.000000</td>\n",
       "      <td>2015.000000</td>\n",
       "      <td>2015.000000</td>\n",
       "      <td>98199.000000</td>\n",
       "      <td>47.777600</td>\n",
       "      <td>-121.315000</td>\n",
       "      <td>6210.000000</td>\n",
       "      <td>871200.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id          date      bedrooms     bathrooms   sqft_living  \\\n",
       "count  2.161300e+04  21613.000000  21613.000000  21613.000000  21613.000000   \n",
       "mean   4.580302e+09   2014.322954      3.370842      2.114757   2079.899736   \n",
       "std    2.876566e+09      0.467616      0.930062      0.770163    918.440897   \n",
       "min    1.000102e+06   2014.000000      0.000000      0.000000    290.000000   \n",
       "25%    2.123049e+09   2014.000000      3.000000      1.750000   1427.000000   \n",
       "50%    3.904930e+09   2014.000000      3.000000      2.250000   1910.000000   \n",
       "75%    7.308900e+09   2015.000000      4.000000      2.500000   2550.000000   \n",
       "max    9.900000e+09   2015.000000     33.000000      8.000000  13540.000000   \n",
       "\n",
       "           sqft_lot        floors    waterfront          view     condition  \\\n",
       "count  2.161300e+04  21613.000000  21613.000000  21613.000000  21613.000000   \n",
       "mean   1.510697e+04      1.494309      0.007542      0.234303      3.409430   \n",
       "std    4.142051e+04      0.539989      0.086517      0.766318      0.650743   \n",
       "min    5.200000e+02      1.000000      0.000000      0.000000      1.000000   \n",
       "25%    5.040000e+03      1.000000      0.000000      0.000000      3.000000   \n",
       "50%    7.618000e+03      1.500000      0.000000      0.000000      3.000000   \n",
       "75%    1.068800e+04      2.000000      0.000000      0.000000      4.000000   \n",
       "max    1.651359e+06      3.500000      1.000000      4.000000      5.000000   \n",
       "\n",
       "              grade    sqft_above  sqft_basement      yr_built  yr_renovated  \\\n",
       "count  21613.000000  21613.000000   21613.000000  21613.000000  21613.000000   \n",
       "mean       7.656873   1788.390691     291.509045   1971.005136     84.402258   \n",
       "std        1.175459    828.090978     442.575043     29.373411    401.679240   \n",
       "min        1.000000    290.000000       0.000000   1900.000000      0.000000   \n",
       "25%        7.000000   1190.000000       0.000000   1951.000000      0.000000   \n",
       "50%        7.000000   1560.000000       0.000000   1975.000000      0.000000   \n",
       "75%        8.000000   2210.000000     560.000000   1997.000000      0.000000   \n",
       "max       13.000000   9410.000000    4820.000000   2015.000000   2015.000000   \n",
       "\n",
       "            zipcode           lat          long  sqft_living15     sqft_lot15  \n",
       "count  21613.000000  21613.000000  21613.000000   21613.000000   21613.000000  \n",
       "mean   98077.939805     47.560053   -122.213896    1986.552492   12768.455652  \n",
       "std       53.505026      0.138564      0.140828     685.391304   27304.179631  \n",
       "min    98001.000000     47.155900   -122.519000     399.000000     651.000000  \n",
       "25%    98033.000000     47.471000   -122.328000    1490.000000    5100.000000  \n",
       "50%    98065.000000     47.571800   -122.230000    1840.000000    7620.000000  \n",
       "75%    98118.000000     47.678000   -122.125000    2360.000000   10083.000000  \n",
       "max    98199.000000     47.777600   -121.315000    6210.000000  871200.000000  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76e1be89",
   "metadata": {},
   "source": [
    "Отбор признаков с высокой дисперсией"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0b6d24fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21613, 11)\n",
      "0.7526999884574543\n"
     ]
    }
   ],
   "source": [
    "vt = VarianceThreshold(1)\n",
    "X_vt = vt.fit_transform(X)\n",
    "print(X_vt.shape)\n",
    "test(X_vt, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e8d28814",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sqft_living</th>\n",
       "      <th>sqft_lot</th>\n",
       "      <th>grade</th>\n",
       "      <th>sqft_above</th>\n",
       "      <th>sqft_basement</th>\n",
       "      <th>yr_built</th>\n",
       "      <th>yr_renovated</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>sqft_living15</th>\n",
       "      <th>sqft_lot15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21608</th>\n",
       "      <td>2.630000e+08</td>\n",
       "      <td>1530.0</td>\n",
       "      <td>1131.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1530.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2009.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>98103.0</td>\n",
       "      <td>1530.0</td>\n",
       "      <td>1509.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21609</th>\n",
       "      <td>6.600060e+09</td>\n",
       "      <td>2310.0</td>\n",
       "      <td>5813.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2310.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>98146.0</td>\n",
       "      <td>1830.0</td>\n",
       "      <td>7200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21610</th>\n",
       "      <td>1.523300e+09</td>\n",
       "      <td>1020.0</td>\n",
       "      <td>1350.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1020.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2009.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>98144.0</td>\n",
       "      <td>1020.0</td>\n",
       "      <td>2007.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21611</th>\n",
       "      <td>2.913101e+08</td>\n",
       "      <td>1600.0</td>\n",
       "      <td>2388.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1600.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2004.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>98027.0</td>\n",
       "      <td>1410.0</td>\n",
       "      <td>1287.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21612</th>\n",
       "      <td>1.523300e+09</td>\n",
       "      <td>1020.0</td>\n",
       "      <td>1076.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1020.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>98144.0</td>\n",
       "      <td>1020.0</td>\n",
       "      <td>1357.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id  sqft_living  sqft_lot  grade  sqft_above  sqft_basement  \\\n",
       "21608  2.630000e+08       1530.0    1131.0    8.0      1530.0            0.0   \n",
       "21609  6.600060e+09       2310.0    5813.0    8.0      2310.0            0.0   \n",
       "21610  1.523300e+09       1020.0    1350.0    7.0      1020.0            0.0   \n",
       "21611  2.913101e+08       1600.0    2388.0    8.0      1600.0            0.0   \n",
       "21612  1.523300e+09       1020.0    1076.0    7.0      1020.0            0.0   \n",
       "\n",
       "       yr_built  yr_renovated  zipcode  sqft_living15  sqft_lot15  \n",
       "21608    2009.0           0.0  98103.0         1530.0      1509.0  \n",
       "21609    2014.0           0.0  98146.0         1830.0      7200.0  \n",
       "21610    2009.0           0.0  98144.0         1020.0      2007.0  \n",
       "21611    2004.0           0.0  98027.0         1410.0      1287.0  \n",
       "21612    2008.0           0.0  98144.0         1020.0      1357.0  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_vt = pd.DataFrame(X_vt, columns=vt.get_feature_names_out())\n",
    "X_vt.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f618347",
   "metadata": {},
   "source": [
    "Одномерный отбор"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c2bed1e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k= 1\n",
      "0.4616464097218238\n",
      "----------------\n",
      "k= 2\n",
      "0.49616792677530275\n",
      "----------------\n",
      "k= 3\n",
      "0.49132343306482407\n",
      "----------------\n",
      "k= 4\n",
      "0.5384178361072368\n",
      "----------------\n",
      "k= 5\n",
      "0.523500858859091\n",
      "----------------\n",
      "k= 6\n",
      "0.7029340240439812\n",
      "----------------\n",
      "k= 7\n",
      "0.7660554478204126\n",
      "----------------\n",
      "k= 8\n",
      "0.7939691690607483\n",
      "----------------\n",
      "k= 9\n",
      "0.7818459108778549\n",
      "----------------\n",
      "k= 10\n",
      "0.7880723510259378\n",
      "----------------\n",
      "k= 11\n",
      "0.7886288952487612\n",
      "----------------\n",
      "k= 12\n",
      "0.8003188849781482\n",
      "----------------\n",
      "k= 13\n",
      "0.7809492459171251\n",
      "----------------\n",
      "k= 14\n",
      "0.8253475224032716\n",
      "----------------\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,15):\n",
    "    skb = SelectKBest(k=i)\n",
    "    X_skb = skb.fit_transform(X, y)\n",
    "    print(\"k=\", i)\n",
    "    test(X_skb, y)\n",
    "    print(\"----------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "55e69f97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7887964181766031\n",
      "['bathrooms' 'sqft_living' 'waterfront' 'view' 'grade' 'sqft_above' 'lat'\n",
      " 'sqft_living15']\n"
     ]
    }
   ],
   "source": [
    "bestIthink = SelectKBest(k=8)\n",
    "Uhu = bestIthink.fit_transform(X, y)\n",
    "test(Uhu, y)\n",
    "print(bestIthink.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60b7f0ce",
   "metadata": {},
   "source": [
    "Рекурсивный отбор"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "faee5680",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = DecisionTreeRegressor().fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f073311d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5659326028162486\n",
      "0.5023738335335044\n",
      "0.7021215706037345\n",
      "0.8127963410661972\n",
      "0.8605254136879803\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 6):\n",
    "    rfe = RFE(estimator=tree, n_features_to_select=i, step=100).fit(X, y)\n",
    "    X_rfe = pd.DataFrame(rfe.transform(X), columns=rfe.get_feature_names_out())\n",
    "    test(X_rfe, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "61609d8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8696861165046279\n",
      "['sqft_living' 'grade' 'lat' 'long']\n"
     ]
    }
   ],
   "source": [
    "bestRFEIThink = RFE(estimator=tree, n_features_to_select=4, step=100).fit(X, y)\n",
    "X_rfe = pd.DataFrame(rfe.transform(X), columns=rfe.get_feature_names_out())\n",
    "test(X_rfe, y)\n",
    "print(bestRFEIThink.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a72eb324",
   "metadata": {},
   "source": [
    "Метод главных компонент"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1cdd0271",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21613, 1)\n",
      "0.999999999707631\n",
      "0.2874383793577444\n",
      "-------------\n",
      "(21613, 2)\n",
      "0.9999999999654228\n",
      "0.23882867632552507\n",
      "-------------\n",
      "(21613, 3)\n",
      "0.9999999999997228\n",
      "0.13517037151994915\n",
      "-------------\n",
      "(21613, 4)\n",
      "0.9999999999999264\n",
      "0.3915105368043117\n",
      "-------------\n",
      "(21613, 5)\n",
      "0.99999999999996\n",
      "0.5217772602699426\n",
      "-------------\n",
      "(21613, 6)\n",
      "0.9999999999999803\n",
      "0.5056074208131489\n",
      "-------------\n",
      "(21613, 7)\n",
      "0.9999999999999982\n",
      "0.511905578472603\n",
      "-------------\n",
      "(21613, 8)\n",
      "0.9999999999999986\n",
      "0.6075384013575386\n",
      "-------------\n",
      "(21613, 9)\n",
      "0.9999999999999982\n",
      "0.5708472559867821\n",
      "-------------\n",
      "(21613, 10)\n",
      "0.9999999999999982\n",
      "0.6322992668726212\n",
      "-------------\n",
      "(21613, 11)\n",
      "0.9999999999999982\n",
      "0.6459332067154784\n",
      "-------------\n",
      "(21613, 12)\n",
      "0.9999999999999982\n",
      "0.6670309486159651\n",
      "-------------\n",
      "(21613, 13)\n",
      "0.9999999999999982\n",
      "0.6740998919169428\n",
      "-------------\n",
      "(21613, 14)\n",
      "0.9999999999999982\n",
      "0.680093836169942\n",
      "-------------\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,15):\n",
    "    pca = PCA(n_components=i)\n",
    "    X_pca = pca.fit_transform(X, y)\n",
    "    print(X_pca.shape)\n",
    "    print(sum(pca.explained_variance_ratio_))\n",
    "    test(X_pca, y)\n",
    "    print(\"-------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d794946b",
   "metadata": {},
   "source": [
    "Нелинейные методы выделения признаков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "70e200a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09418994086880761\n"
     ]
    }
   ],
   "source": [
    "tsne = TSNE(n_components=2)\n",
    "X_tsne = tsne.fit_transform(X[:10000])\n",
    "test(X_tsne, y[:10000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "7ccb2dc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.6865399463069868\n"
     ]
    }
   ],
   "source": [
    "tsne1 = TSNE(n_components=2)\n",
    "X_tsne1 = tsne1.fit_transform(X[:100])\n",
    "test(X_tsne1, y[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "f4fa8c01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.5583405309108314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aron\\Desktop\\Учеба\\4 семестр\\Машинное обучение\\Jupiter nouts\\venv\\lib\\site-packages\\sklearn\\manifold\\_isomap.py:373: UserWarning: The number of connected components of the neighbors graph is 11 > 1. Completing the graph to fit Isomap might be slow. Increase the number of neighbors to avoid this issue.\n",
      "  self._fit_transform(X)\n",
      "C:\\Users\\Aron\\Desktop\\Учеба\\4 семестр\\Машинное обучение\\Jupiter nouts\\venv\\lib\\site-packages\\scipy\\sparse\\_index.py:103: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  self._set_intXint(row, col, x.flat[0])\n",
      "C:\\Users\\Aron\\Desktop\\Учеба\\4 семестр\\Машинное обучение\\Jupiter nouts\\venv\\lib\\site-packages\\scipy\\sparse\\_index.py:103: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  self._set_intXint(row, col, x.flat[0])\n",
      "C:\\Users\\Aron\\Desktop\\Учеба\\4 семестр\\Машинное обучение\\Jupiter nouts\\venv\\lib\\site-packages\\scipy\\sparse\\_index.py:103: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  self._set_intXint(row, col, x.flat[0])\n",
      "C:\\Users\\Aron\\Desktop\\Учеба\\4 семестр\\Машинное обучение\\Jupiter nouts\\venv\\lib\\site-packages\\scipy\\sparse\\_index.py:103: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  self._set_intXint(row, col, x.flat[0])\n",
      "C:\\Users\\Aron\\Desktop\\Учеба\\4 семестр\\Машинное обучение\\Jupiter nouts\\venv\\lib\\site-packages\\scipy\\sparse\\_index.py:103: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  self._set_intXint(row, col, x.flat[0])\n",
      "C:\\Users\\Aron\\Desktop\\Учеба\\4 семестр\\Машинное обучение\\Jupiter nouts\\venv\\lib\\site-packages\\scipy\\sparse\\_index.py:103: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  self._set_intXint(row, col, x.flat[0])\n",
      "C:\\Users\\Aron\\Desktop\\Учеба\\4 семестр\\Машинное обучение\\Jupiter nouts\\venv\\lib\\site-packages\\scipy\\sparse\\_index.py:103: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  self._set_intXint(row, col, x.flat[0])\n",
      "C:\\Users\\Aron\\Desktop\\Учеба\\4 семестр\\Машинное обучение\\Jupiter nouts\\venv\\lib\\site-packages\\scipy\\sparse\\_index.py:103: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  self._set_intXint(row, col, x.flat[0])\n",
      "C:\\Users\\Aron\\Desktop\\Учеба\\4 семестр\\Машинное обучение\\Jupiter nouts\\venv\\lib\\site-packages\\scipy\\sparse\\_index.py:103: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  self._set_intXint(row, col, x.flat[0])\n",
      "C:\\Users\\Aron\\Desktop\\Учеба\\4 семестр\\Машинное обучение\\Jupiter nouts\\venv\\lib\\site-packages\\scipy\\sparse\\_index.py:103: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  self._set_intXint(row, col, x.flat[0])\n",
      "C:\\Users\\Aron\\Desktop\\Учеба\\4 семестр\\Машинное обучение\\Jupiter nouts\\venv\\lib\\site-packages\\scipy\\sparse\\_index.py:103: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  self._set_intXint(row, col, x.flat[0])\n",
      "C:\\Users\\Aron\\Desktop\\Учеба\\4 семестр\\Машинное обучение\\Jupiter nouts\\venv\\lib\\site-packages\\scipy\\sparse\\_index.py:103: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  self._set_intXint(row, col, x.flat[0])\n",
      "C:\\Users\\Aron\\Desktop\\Учеба\\4 семестр\\Машинное обучение\\Jupiter nouts\\venv\\lib\\site-packages\\scipy\\sparse\\_index.py:103: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  self._set_intXint(row, col, x.flat[0])\n",
      "C:\\Users\\Aron\\Desktop\\Учеба\\4 семестр\\Машинное обучение\\Jupiter nouts\\venv\\lib\\site-packages\\scipy\\sparse\\_index.py:103: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  self._set_intXint(row, col, x.flat[0])\n",
      "C:\\Users\\Aron\\Desktop\\Учеба\\4 семестр\\Машинное обучение\\Jupiter nouts\\venv\\lib\\site-packages\\scipy\\sparse\\_index.py:103: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  self._set_intXint(row, col, x.flat[0])\n",
      "C:\\Users\\Aron\\Desktop\\Учеба\\4 семестр\\Машинное обучение\\Jupiter nouts\\venv\\lib\\site-packages\\scipy\\sparse\\_index.py:103: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  self._set_intXint(row, col, x.flat[0])\n",
      "C:\\Users\\Aron\\Desktop\\Учеба\\4 семестр\\Машинное обучение\\Jupiter nouts\\venv\\lib\\site-packages\\scipy\\sparse\\_index.py:103: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  self._set_intXint(row, col, x.flat[0])\n",
      "C:\\Users\\Aron\\Desktop\\Учеба\\4 семестр\\Машинное обучение\\Jupiter nouts\\venv\\lib\\site-packages\\scipy\\sparse\\_index.py:103: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  self._set_intXint(row, col, x.flat[0])\n",
      "C:\\Users\\Aron\\Desktop\\Учеба\\4 семестр\\Машинное обучение\\Jupiter nouts\\venv\\lib\\site-packages\\scipy\\sparse\\_index.py:103: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  self._set_intXint(row, col, x.flat[0])\n",
      "C:\\Users\\Aron\\Desktop\\Учеба\\4 семестр\\Машинное обучение\\Jupiter nouts\\venv\\lib\\site-packages\\scipy\\sparse\\_index.py:103: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  self._set_intXint(row, col, x.flat[0])\n",
      "C:\\Users\\Aron\\Desktop\\Учеба\\4 семестр\\Машинное обучение\\Jupiter nouts\\venv\\lib\\site-packages\\scipy\\sparse\\_index.py:103: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  self._set_intXint(row, col, x.flat[0])\n",
      "C:\\Users\\Aron\\Desktop\\Учеба\\4 семестр\\Машинное обучение\\Jupiter nouts\\venv\\lib\\site-packages\\scipy\\sparse\\_index.py:103: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  self._set_intXint(row, col, x.flat[0])\n",
      "C:\\Users\\Aron\\Desktop\\Учеба\\4 семестр\\Машинное обучение\\Jupiter nouts\\venv\\lib\\site-packages\\scipy\\sparse\\_index.py:103: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  self._set_intXint(row, col, x.flat[0])\n",
      "C:\\Users\\Aron\\Desktop\\Учеба\\4 семестр\\Машинное обучение\\Jupiter nouts\\venv\\lib\\site-packages\\scipy\\sparse\\_index.py:103: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  self._set_intXint(row, col, x.flat[0])\n",
      "C:\\Users\\Aron\\Desktop\\Учеба\\4 семестр\\Машинное обучение\\Jupiter nouts\\venv\\lib\\site-packages\\scipy\\sparse\\_index.py:103: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  self._set_intXint(row, col, x.flat[0])\n",
      "C:\\Users\\Aron\\Desktop\\Учеба\\4 семестр\\Машинное обучение\\Jupiter nouts\\venv\\lib\\site-packages\\scipy\\sparse\\_index.py:103: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  self._set_intXint(row, col, x.flat[0])\n",
      "C:\\Users\\Aron\\Desktop\\Учеба\\4 семестр\\Машинное обучение\\Jupiter nouts\\venv\\lib\\site-packages\\scipy\\sparse\\_index.py:103: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  self._set_intXint(row, col, x.flat[0])\n",
      "C:\\Users\\Aron\\Desktop\\Учеба\\4 семестр\\Машинное обучение\\Jupiter nouts\\venv\\lib\\site-packages\\scipy\\sparse\\_index.py:103: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  self._set_intXint(row, col, x.flat[0])\n",
      "C:\\Users\\Aron\\Desktop\\Учеба\\4 семестр\\Машинное обучение\\Jupiter nouts\\venv\\lib\\site-packages\\scipy\\sparse\\_index.py:103: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  self._set_intXint(row, col, x.flat[0])\n",
      "C:\\Users\\Aron\\Desktop\\Учеба\\4 семестр\\Машинное обучение\\Jupiter nouts\\venv\\lib\\site-packages\\scipy\\sparse\\_index.py:103: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  self._set_intXint(row, col, x.flat[0])\n",
      "C:\\Users\\Aron\\Desktop\\Учеба\\4 семестр\\Машинное обучение\\Jupiter nouts\\venv\\lib\\site-packages\\scipy\\sparse\\_index.py:103: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  self._set_intXint(row, col, x.flat[0])\n",
      "C:\\Users\\Aron\\Desktop\\Учеба\\4 семестр\\Машинное обучение\\Jupiter nouts\\venv\\lib\\site-packages\\scipy\\sparse\\_index.py:103: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  self._set_intXint(row, col, x.flat[0])\n",
      "C:\\Users\\Aron\\Desktop\\Учеба\\4 семестр\\Машинное обучение\\Jupiter nouts\\venv\\lib\\site-packages\\scipy\\sparse\\_index.py:103: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  self._set_intXint(row, col, x.flat[0])\n",
      "C:\\Users\\Aron\\Desktop\\Учеба\\4 семестр\\Машинное обучение\\Jupiter nouts\\venv\\lib\\site-packages\\scipy\\sparse\\_index.py:103: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  self._set_intXint(row, col, x.flat[0])\n",
      "C:\\Users\\Aron\\Desktop\\Учеба\\4 семестр\\Машинное обучение\\Jupiter nouts\\venv\\lib\\site-packages\\scipy\\sparse\\_index.py:103: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  self._set_intXint(row, col, x.flat[0])\n",
      "C:\\Users\\Aron\\Desktop\\Учеба\\4 семестр\\Машинное обучение\\Jupiter nouts\\venv\\lib\\site-packages\\scipy\\sparse\\_index.py:103: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  self._set_intXint(row, col, x.flat[0])\n",
      "C:\\Users\\Aron\\Desktop\\Учеба\\4 семестр\\Машинное обучение\\Jupiter nouts\\venv\\lib\\site-packages\\scipy\\sparse\\_index.py:103: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  self._set_intXint(row, col, x.flat[0])\n",
      "C:\\Users\\Aron\\Desktop\\Учеба\\4 семестр\\Машинное обучение\\Jupiter nouts\\venv\\lib\\site-packages\\scipy\\sparse\\_index.py:103: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  self._set_intXint(row, col, x.flat[0])\n",
      "C:\\Users\\Aron\\Desktop\\Учеба\\4 семестр\\Машинное обучение\\Jupiter nouts\\venv\\lib\\site-packages\\scipy\\sparse\\_index.py:103: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  self._set_intXint(row, col, x.flat[0])\n",
      "C:\\Users\\Aron\\Desktop\\Учеба\\4 семестр\\Машинное обучение\\Jupiter nouts\\venv\\lib\\site-packages\\scipy\\sparse\\_index.py:103: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  self._set_intXint(row, col, x.flat[0])\n",
      "C:\\Users\\Aron\\Desktop\\Учеба\\4 семестр\\Машинное обучение\\Jupiter nouts\\venv\\lib\\site-packages\\scipy\\sparse\\_index.py:103: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  self._set_intXint(row, col, x.flat[0])\n",
      "C:\\Users\\Aron\\Desktop\\Учеба\\4 семестр\\Машинное обучение\\Jupiter nouts\\venv\\lib\\site-packages\\scipy\\sparse\\_index.py:103: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  self._set_intXint(row, col, x.flat[0])\n",
      "C:\\Users\\Aron\\Desktop\\Учеба\\4 семестр\\Машинное обучение\\Jupiter nouts\\venv\\lib\\site-packages\\scipy\\sparse\\_index.py:103: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  self._set_intXint(row, col, x.flat[0])\n",
      "C:\\Users\\Aron\\Desktop\\Учеба\\4 семестр\\Машинное обучение\\Jupiter nouts\\venv\\lib\\site-packages\\scipy\\sparse\\_index.py:103: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  self._set_intXint(row, col, x.flat[0])\n",
      "C:\\Users\\Aron\\Desktop\\Учеба\\4 семестр\\Машинное обучение\\Jupiter nouts\\venv\\lib\\site-packages\\scipy\\sparse\\_index.py:103: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  self._set_intXint(row, col, x.flat[0])\n",
      "C:\\Users\\Aron\\Desktop\\Учеба\\4 семестр\\Машинное обучение\\Jupiter nouts\\venv\\lib\\site-packages\\scipy\\sparse\\_index.py:103: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  self._set_intXint(row, col, x.flat[0])\n",
      "C:\\Users\\Aron\\Desktop\\Учеба\\4 семестр\\Машинное обучение\\Jupiter nouts\\venv\\lib\\site-packages\\scipy\\sparse\\_index.py:103: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  self._set_intXint(row, col, x.flat[0])\n",
      "C:\\Users\\Aron\\Desktop\\Учеба\\4 семестр\\Машинное обучение\\Jupiter nouts\\venv\\lib\\site-packages\\scipy\\sparse\\_index.py:103: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  self._set_intXint(row, col, x.flat[0])\n",
      "C:\\Users\\Aron\\Desktop\\Учеба\\4 семестр\\Машинное обучение\\Jupiter nouts\\venv\\lib\\site-packages\\scipy\\sparse\\_index.py:103: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  self._set_intXint(row, col, x.flat[0])\n",
      "C:\\Users\\Aron\\Desktop\\Учеба\\4 семестр\\Машинное обучение\\Jupiter nouts\\venv\\lib\\site-packages\\scipy\\sparse\\_index.py:103: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  self._set_intXint(row, col, x.flat[0])\n",
      "C:\\Users\\Aron\\Desktop\\Учеба\\4 семестр\\Машинное обучение\\Jupiter nouts\\venv\\lib\\site-packages\\scipy\\sparse\\_index.py:103: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  self._set_intXint(row, col, x.flat[0])\n",
      "C:\\Users\\Aron\\Desktop\\Учеба\\4 семестр\\Машинное обучение\\Jupiter nouts\\venv\\lib\\site-packages\\scipy\\sparse\\_index.py:103: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  self._set_intXint(row, col, x.flat[0])\n",
      "C:\\Users\\Aron\\Desktop\\Учеба\\4 семестр\\Машинное обучение\\Jupiter nouts\\venv\\lib\\site-packages\\scipy\\sparse\\_index.py:103: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  self._set_intXint(row, col, x.flat[0])\n",
      "C:\\Users\\Aron\\Desktop\\Учеба\\4 семестр\\Машинное обучение\\Jupiter nouts\\venv\\lib\\site-packages\\scipy\\sparse\\_index.py:103: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  self._set_intXint(row, col, x.flat[0])\n",
      "C:\\Users\\Aron\\Desktop\\Учеба\\4 семестр\\Машинное обучение\\Jupiter nouts\\venv\\lib\\site-packages\\scipy\\sparse\\_index.py:103: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  self._set_intXint(row, col, x.flat[0])\n"
     ]
    }
   ],
   "source": [
    "isomap = Isomap()\n",
    "X_isomap = isomap.fit_transform(X[:360])\n",
    "test(X_isomap, y[:360])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "437c29ae",
   "metadata": {},
   "source": [
    "Понижение размерности для классификации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "ddbece39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(87403, 8) (87403, 8)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>distance_from_home</th>\n",
       "      <th>distance_from_last_transaction</th>\n",
       "      <th>ratio_to_median_purchase_price</th>\n",
       "      <th>repeat_retailer</th>\n",
       "      <th>used_chip</th>\n",
       "      <th>used_pin_number</th>\n",
       "      <th>online_order</th>\n",
       "      <th>fraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>703778</th>\n",
       "      <td>0.187051</td>\n",
       "      <td>3.458460</td>\n",
       "      <td>0.497488</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>891579</th>\n",
       "      <td>163.810660</td>\n",
       "      <td>13.533889</td>\n",
       "      <td>2.601019</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>514011</th>\n",
       "      <td>108.305991</td>\n",
       "      <td>4.717771</td>\n",
       "      <td>4.575967</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>662552</th>\n",
       "      <td>48.113318</td>\n",
       "      <td>2.641942</td>\n",
       "      <td>0.398721</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>705981</th>\n",
       "      <td>2.832829</td>\n",
       "      <td>1.590991</td>\n",
       "      <td>1.607049</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>632070</th>\n",
       "      <td>20.521114</td>\n",
       "      <td>0.233488</td>\n",
       "      <td>6.017318</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>716534</th>\n",
       "      <td>11.771778</td>\n",
       "      <td>4.091279</td>\n",
       "      <td>1.289488</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>738420</th>\n",
       "      <td>29.093223</td>\n",
       "      <td>0.929251</td>\n",
       "      <td>1.028641</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>718416</th>\n",
       "      <td>49.864353</td>\n",
       "      <td>2.117588</td>\n",
       "      <td>5.070390</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67252</th>\n",
       "      <td>3.462460</td>\n",
       "      <td>67.653469</td>\n",
       "      <td>0.778775</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>174806 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        distance_from_home  distance_from_last_transaction  \\\n",
       "703778            0.187051                        3.458460   \n",
       "891579          163.810660                       13.533889   \n",
       "514011          108.305991                        4.717771   \n",
       "662552           48.113318                        2.641942   \n",
       "705981            2.832829                        1.590991   \n",
       "...                    ...                             ...   \n",
       "632070           20.521114                        0.233488   \n",
       "716534           11.771778                        4.091279   \n",
       "738420           29.093223                        0.929251   \n",
       "718416           49.864353                        2.117588   \n",
       "67252             3.462460                       67.653469   \n",
       "\n",
       "        ratio_to_median_purchase_price  repeat_retailer  used_chip  \\\n",
       "703778                        0.497488              0.0        0.0   \n",
       "891579                        2.601019              1.0        0.0   \n",
       "514011                        4.575967              1.0        0.0   \n",
       "662552                        0.398721              1.0        0.0   \n",
       "705981                        1.607049              1.0        1.0   \n",
       "...                                ...              ...        ...   \n",
       "632070                        6.017318              1.0        0.0   \n",
       "716534                        1.289488              1.0        1.0   \n",
       "738420                        1.028641              1.0        0.0   \n",
       "718416                        5.070390              1.0        0.0   \n",
       "67252                         0.778775              1.0        0.0   \n",
       "\n",
       "        used_pin_number  online_order  fraud  \n",
       "703778              0.0           0.0    0.0  \n",
       "891579              0.0           1.0    1.0  \n",
       "514011              0.0           1.0    1.0  \n",
       "662552              0.0           1.0    0.0  \n",
       "705981              0.0           1.0    0.0  \n",
       "...                 ...           ...    ...  \n",
       "632070              0.0           1.0    1.0  \n",
       "716534              0.0           1.0    0.0  \n",
       "738420              0.0           0.0    0.0  \n",
       "718416              0.0           0.0    0.0  \n",
       "67252               0.0           1.0    1.0  \n",
       "\n",
       "[174806 rows x 8 columns]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_classification = pd.read_csv(\"../data/card_transdata.csv\")\n",
    "data_classification = data_classification.sort_values(by='fraud', ascending=False)\n",
    "data_classification = data_classification[:(data_classification[data_classification['fraud'] == 1].shape[0]*2)]\n",
    "print(data_classification[data_classification['fraud'] == 0].shape, data_classification[data_classification['fraud'] == 1].shape)\n",
    "data_classification = data_classification.sample(frac=1)\n",
    "x_under = data_classification.drop([\"fraud\"], axis = 1)\n",
    "y_under = data_classification[\"fraud\"]\n",
    "data_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "f3bacf07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def testC(x, Y):\n",
    "  X_train, X_test, y_train, y_test = train_test_split(x, Y, test_size=0.15, shuffle=False)\n",
    "  bag = BaggingClassifier().fit(X_train, y_train)\n",
    "  print(classification_report(y_test, bag.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "095e75fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00     13361\n",
      "         1.0       1.00      1.00      1.00     12860\n",
      "\n",
      "    accuracy                           1.00     26221\n",
      "   macro avg       1.00      1.00      1.00     26221\n",
      "weighted avg       1.00      1.00      1.00     26221\n",
      "\n"
     ]
    }
   ],
   "source": [
    "testC(x_under, y_under)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "6c6ee4a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(174806, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>distance_from_home</th>\n",
       "      <th>distance_from_last_transaction</th>\n",
       "      <th>ratio_to_median_purchase_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.187051</td>\n",
       "      <td>3.458460</td>\n",
       "      <td>0.497488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>163.810660</td>\n",
       "      <td>13.533889</td>\n",
       "      <td>2.601019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>108.305991</td>\n",
       "      <td>4.717771</td>\n",
       "      <td>4.575967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>48.113318</td>\n",
       "      <td>2.641942</td>\n",
       "      <td>0.398721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.832829</td>\n",
       "      <td>1.590991</td>\n",
       "      <td>1.607049</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   distance_from_home  distance_from_last_transaction  \\\n",
       "0            0.187051                        3.458460   \n",
       "1          163.810660                       13.533889   \n",
       "2          108.305991                        4.717771   \n",
       "3           48.113318                        2.641942   \n",
       "4            2.832829                        1.590991   \n",
       "\n",
       "   ratio_to_median_purchase_price  \n",
       "0                        0.497488  \n",
       "1                        2.601019  \n",
       "2                        4.575967  \n",
       "3                        0.398721  \n",
       "4                        1.607049  "
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vt1 = VarianceThreshold(2)\n",
    "X_vtC = vt1.fit_transform(x_under)\n",
    "print(X_vtC.shape)\n",
    "X_vtC = pd.DataFrame(X_vtC, columns=vt1.get_feature_names_out())\n",
    "X_vtC.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "8e3ccf16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00     13361\n",
      "         1.0       1.00      1.00      1.00     12860\n",
      "\n",
      "    accuracy                           1.00     26221\n",
      "   macro avg       1.00      1.00      1.00     26221\n",
      "weighted avg       1.00      1.00      1.00     26221\n",
      "\n"
     ]
    }
   ],
   "source": [
    "testC(x_under, y_under)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c35285e9",
   "metadata": {},
   "source": [
    "Одномерный отбор признаков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "062b8524",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count_of_features= 1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.77      0.79      0.78     13361\n",
      "         1.0       0.77      0.75      0.76     12860\n",
      "\n",
      "    accuracy                           0.77     26221\n",
      "   macro avg       0.77      0.77      0.77     26221\n",
      "weighted avg       0.77      0.77      0.77     26221\n",
      "\n",
      "['ratio_to_median_purchase_price']\n",
      "count_of_features= 2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.79      0.81      0.80     13361\n",
      "         1.0       0.80      0.78      0.79     12860\n",
      "\n",
      "    accuracy                           0.80     26221\n",
      "   macro avg       0.80      0.80      0.80     26221\n",
      "weighted avg       0.80      0.80      0.80     26221\n",
      "\n",
      "['ratio_to_median_purchase_price' 'online_order']\n",
      "count_of_features= 3\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.80      0.82      0.81     13361\n",
      "         1.0       0.81      0.79      0.80     12860\n",
      "\n",
      "    accuracy                           0.81     26221\n",
      "   macro avg       0.81      0.81      0.81     26221\n",
      "weighted avg       0.81      0.81      0.81     26221\n",
      "\n",
      "['ratio_to_median_purchase_price' 'used_pin_number' 'online_order']\n",
      "count_of_features= 4\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.98      0.96     13361\n",
      "         1.0       0.98      0.93      0.95     12860\n",
      "\n",
      "    accuracy                           0.96     26221\n",
      "   macro avg       0.96      0.96      0.96     26221\n",
      "weighted avg       0.96      0.96      0.96     26221\n",
      "\n",
      "['distance_from_home' 'ratio_to_median_purchase_price' 'used_pin_number'\n",
      " 'online_order']\n",
      "count_of_features= 5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.99      0.99     13361\n",
      "         1.0       0.98      1.00      0.99     12860\n",
      "\n",
      "    accuracy                           0.99     26221\n",
      "   macro avg       0.99      0.99      0.99     26221\n",
      "weighted avg       0.99      0.99      0.99     26221\n",
      "\n",
      "['distance_from_home' 'distance_from_last_transaction'\n",
      " 'ratio_to_median_purchase_price' 'used_pin_number' 'online_order']\n",
      "count_of_features= 6\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00     13361\n",
      "         1.0       1.00      1.00      1.00     12860\n",
      "\n",
      "    accuracy                           1.00     26221\n",
      "   macro avg       1.00      1.00      1.00     26221\n",
      "weighted avg       1.00      1.00      1.00     26221\n",
      "\n",
      "['distance_from_home' 'distance_from_last_transaction'\n",
      " 'ratio_to_median_purchase_price' 'used_chip' 'used_pin_number'\n",
      " 'online_order']\n",
      "count_of_features= 7\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00     13361\n",
      "         1.0       1.00      1.00      1.00     12860\n",
      "\n",
      "    accuracy                           1.00     26221\n",
      "   macro avg       1.00      1.00      1.00     26221\n",
      "weighted avg       1.00      1.00      1.00     26221\n",
      "\n",
      "['distance_from_home' 'distance_from_last_transaction'\n",
      " 'ratio_to_median_purchase_price' 'repeat_retailer' 'used_chip'\n",
      " 'used_pin_number' 'online_order']\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,8):\n",
    "    print(\"count_of_features=\",i)\n",
    "    skb = SelectKBest(k=i)\n",
    "    X_skb = skb.fit_transform(x_under, y_under)\n",
    "    testC(X_skb, y_under)\n",
    "    print(skb.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d106cf4b",
   "metadata": {},
   "source": [
    "Рекурсивный отбор признаков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "bd705eab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.77      0.79      0.78     13361\n",
      "         1.0       0.77      0.75      0.76     12860\n",
      "\n",
      "    accuracy                           0.77     26221\n",
      "   macro avg       0.77      0.77      0.77     26221\n",
      "weighted avg       0.77      0.77      0.77     26221\n",
      "\n",
      "['ratio_to_median_purchase_price']\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.92      0.93      0.93     13361\n",
      "         1.0       0.92      0.92      0.92     12860\n",
      "\n",
      "    accuracy                           0.92     26221\n",
      "   macro avg       0.92      0.92      0.92     26221\n",
      "weighted avg       0.92      0.92      0.92     26221\n",
      "\n",
      "['distance_from_home' 'ratio_to_median_purchase_price']\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.92      0.95     13361\n",
      "         1.0       0.92      0.99      0.95     12860\n",
      "\n",
      "    accuracy                           0.95     26221\n",
      "   macro avg       0.95      0.95      0.95     26221\n",
      "weighted avg       0.96      0.95      0.95     26221\n",
      "\n",
      "['distance_from_home' 'distance_from_last_transaction'\n",
      " 'ratio_to_median_purchase_price']\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.98      0.99     13361\n",
      "         1.0       0.97      1.00      0.99     12860\n",
      "\n",
      "    accuracy                           0.99     26221\n",
      "   macro avg       0.99      0.99      0.99     26221\n",
      "weighted avg       0.99      0.99      0.99     26221\n",
      "\n",
      "['distance_from_home' 'distance_from_last_transaction'\n",
      " 'ratio_to_median_purchase_price' 'online_order']\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.99      1.00     13361\n",
      "         1.0       0.99      1.00      1.00     12860\n",
      "\n",
      "    accuracy                           1.00     26221\n",
      "   macro avg       1.00      1.00      1.00     26221\n",
      "weighted avg       1.00      1.00      1.00     26221\n",
      "\n",
      "['distance_from_home' 'distance_from_last_transaction'\n",
      " 'ratio_to_median_purchase_price' 'used_chip' 'online_order']\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00     13361\n",
      "         1.0       1.00      1.00      1.00     12860\n",
      "\n",
      "    accuracy                           1.00     26221\n",
      "   macro avg       1.00      1.00      1.00     26221\n",
      "weighted avg       1.00      1.00      1.00     26221\n",
      "\n",
      "['distance_from_home' 'distance_from_last_transaction'\n",
      " 'ratio_to_median_purchase_price' 'used_chip' 'used_pin_number'\n",
      " 'online_order']\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00     13361\n",
      "         1.0       1.00      1.00      1.00     12860\n",
      "\n",
      "    accuracy                           1.00     26221\n",
      "   macro avg       1.00      1.00      1.00     26221\n",
      "weighted avg       1.00      1.00      1.00     26221\n",
      "\n",
      "['distance_from_home' 'distance_from_last_transaction'\n",
      " 'ratio_to_median_purchase_price' 'repeat_retailer' 'used_chip'\n",
      " 'used_pin_number' 'online_order']\n"
     ]
    }
   ],
   "source": [
    "treeC = DecisionTreeClassifier().fit(x_under, y_under)\n",
    "for i in range(1,8):\n",
    "    rfe = RFE(estimator=treeC, n_features_to_select=i, step=1).fit(x_under, y_under)\n",
    "    X_rfe = pd.DataFrame(rfe.transform(x_under), columns=rfe.get_feature_names_out())\n",
    "    testC(X_rfe, y_under)\n",
    "    print(rfe.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3ddc6fe",
   "metadata": {},
   "source": [
    "Метод главных компонент"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "3882aba2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(174806, 3)\n"
     ]
    }
   ],
   "source": [
    "pca = PCA(n_components=3)\n",
    "X_pca = pca.fit_transform(x_under, y_under)\n",
    "print(X_pca.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "11111e8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9999560236921603"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "8992a874",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.92      0.95     13361\n",
      "         1.0       0.92      0.99      0.95     12860\n",
      "\n",
      "    accuracy                           0.95     26221\n",
      "   macro avg       0.96      0.95      0.95     26221\n",
      "weighted avg       0.96      0.95      0.95     26221\n",
      "\n"
     ]
    }
   ],
   "source": [
    "testC(X_pca, y_under)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1477b7c2",
   "metadata": {},
   "source": [
    "Нелинейные методы выделения признаков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "3ca2b5d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.92      0.90      0.91       225\n",
      "         1.0       0.90      0.92      0.91       225\n",
      "\n",
      "    accuracy                           0.91       450\n",
      "   macro avg       0.91      0.91      0.91       450\n",
      "weighted avg       0.91      0.91      0.91       450\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tsne = TSNE(n_components=2)\n",
    "X_tsne = tsne.fit_transform(x_under[:3000])\n",
    "testC(X_tsne, y_under[:3000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "a7b6a0c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.66      0.77      0.71       225\n",
      "         1.0       0.72      0.60      0.66       225\n",
      "\n",
      "    accuracy                           0.68       450\n",
      "   macro avg       0.69      0.68      0.68       450\n",
      "weighted avg       0.69      0.68      0.68       450\n",
      "\n"
     ]
    }
   ],
   "source": [
    "isomap = Isomap(n_components=2)\n",
    "X_isomap = isomap.fit_transform(x_under[:3000])\n",
    "testC(X_isomap, y_under[:3000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "a6c01a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PCA:\n",
    "\n",
    "    def __init__(self, n_components):\n",
    "        self.n_components = n_components\n",
    "        self.components = None\n",
    "        self.mean = None\n",
    "\n",
    "    def fit(self, X):\n",
    "        self.mean = np.mean(X, axis=0)\n",
    "        X = X -  self.mean\n",
    "\n",
    "        cov = np.cov(X.T)\n",
    "\n",
    "        eigenvectors, eigenvalues = np.linalg.eig(cov)\n",
    "\n",
    "        eigenvectors = eigenvectors.T\n",
    "\n",
    "        idxs = np.argsort(eigenvalues)[::-1]\n",
    "        eigenvalues = eigenvalues[idxs]\n",
    "        eigenvectors = eigenvectors[idxs]\n",
    "\n",
    "        self.components = eigenvectors[:self.n_components]\n",
    "\n",
    "    def transform(self, X):\n",
    "        X = X - self.mean\n",
    "        return np.dot(X, self.components.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "c8ef912d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_classification1 = pd.read_csv(\"../data/card_transdata.csv\")\n",
    "x = data_classification1.drop([\"fraud\"], axis = 1)\n",
    "Y = data_classification1[\"fraud\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "7f768cd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pca = PCA(2)\n",
    "pca.fit(x)\n",
    "X_projected = pca.transform(x)\n",
    "\n",
    "plt.scatter(X_projected[:,0], X_projected[:,1], c=Y);\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "5b2ffd3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.97      0.96    136918\n",
      "         1.0       0.61      0.49      0.54     13082\n",
      "\n",
      "    accuracy                           0.93    150000\n",
      "   macro avg       0.78      0.73      0.75    150000\n",
      "weighted avg       0.92      0.93      0.92    150000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "testC(X_projected, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "fc993682",
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_distance(x1, x2):\n",
    "    return np.sqrt(np.sum((x1-x2)**2))\n",
    "\n",
    "class KMeans:\n",
    "\n",
    "    def __init__(self, K=5, max_iters=100, plot_steps=False):\n",
    "        self.K = K\n",
    "        self.max_iters = max_iters\n",
    "        self.plot_steps = plot_steps\n",
    "\n",
    "        self.clusters = [[] for _ in range(self.K)]\n",
    "\n",
    "        self.centroids = []\n",
    "\n",
    "\n",
    "    def fit_predict(self, X):\n",
    "        self.X = X\n",
    "        self.n_samples, self.n_features = X.shape\n",
    "\n",
    "        random_sample_idxs = np.random.choice(self.n_samples, self.K, replace=False)\n",
    "        self.centroids = [self.X[idx] for idx in random_sample_idxs]\n",
    "\n",
    "        for _ in range(self.max_iters):\n",
    "            self.clusters = self._create_clusters(self.centroids)\n",
    "\n",
    "            if self.plot_steps:\n",
    "                self.plot()\n",
    "\n",
    "            centroids_old = self.centroids\n",
    "            self.centroids = self._get_centroids(self.clusters)\n",
    "\n",
    "            if self._is_converged(centroids_old, self.centroids):\n",
    "                break\n",
    "\n",
    "            if self.plot_steps:\n",
    "                self.plot()\n",
    "        # классификация выборки как индекс их кластеров\n",
    "        return self._get_cluster_labels(self.clusters)\n",
    "\n",
    "\n",
    "    def _get_cluster_labels(self, clusters):\n",
    "        labels = np.empty(self.n_samples)\n",
    "        for cluster_idx, cluster in enumerate(clusters):\n",
    "            for sample_idx in cluster:\n",
    "                labels[sample_idx] = cluster_idx\n",
    "\n",
    "        return labels\n",
    "\n",
    "\n",
    "    def _create_clusters(self, centroids):\n",
    "        clusters = [[] for _ in range(self.K)]\n",
    "        for idx, sample in enumerate(self.X):\n",
    "            centroid_idx = self._closest_centroid(sample, centroids)\n",
    "            clusters[centroid_idx].append(idx)\n",
    "        return clusters\n",
    "\n",
    "    def _closest_centroid(self, sample, centroids):\n",
    "        distances = [euclidean_distance(sample, point) for point in centroids]\n",
    "        closest_idx = np.argmin(distances)\n",
    "        return closest_idx\n",
    "\n",
    "\n",
    "    def _get_centroids(self, clusters):\n",
    "        # присваивание среднего значения кластеров центроидам\n",
    "        centroids = np.zeros((self.K, self.n_features))\n",
    "        for cluster_idx, cluster in enumerate(clusters):\n",
    "            cluster_mean = np.mean(self.X[cluster], axis=0)\n",
    "            centroids[cluster_idx] = cluster_mean\n",
    "        return centroids\n",
    "\n",
    "    def _is_converged(self, centroids_old, centroids):\n",
    "        distances = [euclidean_distance(centroids_old[i], centroids[i]) for i in range(self.K)]\n",
    "        return sum(distances) == 0\n",
    "    \n",
    "    def inertia(self):\n",
    "        dis = []\n",
    "        for i, index in enumerate(self.clusters):\n",
    "            sample = self.X[index].T\n",
    "            for j in range(0, len(sample[0])):\n",
    "              dis.append(euclidean_distance((sample[0][j],sample[1][j]), self.centroids[i]))\n",
    "        itog = [x ** 2 for x in dis]\n",
    "        return sum(itog)\n",
    "\n",
    "    def plot(self):\n",
    "        fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "        for i, index in enumerate(self.clusters):\n",
    "            point = self.X[index].T\n",
    "            ax.scatter(*point)\n",
    "\n",
    "        for point in self.centroids:\n",
    "            ax.scatter(*point, marker=\"x\", color=\"black\", linewidth=2)\n",
    "\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "e34246ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1200x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "clusters = len(np.unique(Y))\n",
    "print(clusters)\n",
    "\n",
    "k = KMeans(K=clusters, max_iters=30, plot_steps=False)\n",
    "k.fit_predict(X_projected)\n",
    "\n",
    "k.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1243cc50",
   "metadata": {},
   "source": [
    "LAST Mission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "da8e4b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegression:\n",
    "\n",
    "    def __init__(self, lr = 0.001, n_iters=10000):\n",
    "        self.lr = lr\n",
    "        self.n_iters = n_iters\n",
    "        self.weights = None\n",
    "        self.bias = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        n_samples, n_features = X.shape\n",
    "        self.weights = np.zeros(n_features)\n",
    "        self.bias = 0\n",
    "\n",
    "        for _ in range(self.n_iters):\n",
    "            y_pred = np.dot(X, self.weights) + self.bias\n",
    "\n",
    "            dw = (1/n_samples) * np.dot(X.T, (y_pred-y))\n",
    "            db = (1/n_samples) * np.sum(y_pred-y)\n",
    "            if self.lr > 0:\n",
    "                self.weights = self.weights - self.lr * dw\n",
    "                self.bias = self.bias - self.lr * db\n",
    "\n",
    "    def predict(self, X):\n",
    "        y_pred = np.dot(X, self.weights) + self.bias\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "18a21d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_regression = pd.read_csv(\"../data/kc_house_data.csv\")\n",
    "data_regression[\"date\"]=data_regression[\"date\"].str[:4]\n",
    "data_regression[\"date\"]=pd.to_numeric(data_regression[\"date\"])\n",
    "y = data_regression[\"price\"]\n",
    "X = data_regression.drop([\"price\"], axis = 1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "afdd37a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aron\\AppData\\Local\\Temp\\ipykernel_20720\\1579064509.py:20: RuntimeWarning: invalid value encountered in subtract\n",
      "  self.weights = self.weights - self.lr * dw\n"
     ]
    }
   ],
   "source": [
    "reg = LinearRegression(lr=0.0001)\n",
    "reg.fit(X_train[:100],y_train[:100])\n",
    "predictions = reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "1346e438",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nan nan nan ... nan nan nan]\n"
     ]
    }
   ],
   "source": [
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e240ec1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
